{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19104e62",
   "metadata": {},
   "source": [
    "# Lightning interface example for a random walk\n",
    "\n",
    "This notebook contains an example of training the TACTiS model on a random walk dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa85db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/nhassen/Documents/ProjectQuant/MyRepos/test/GPT-NeoX-for-Time-Series-Forecasting/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8bc993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from GPT_NEO.lightning_module import TradeBotLightning\n",
    "from GPT_NEO.estimator import TradeBotLightEstimator\n",
    "from GPT_NEO.estimator import TradeBotLightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45592614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gluon.dataset import generate_backtesting_datasets\n",
    "from gluon.metrics import compute_validation_metrics\n",
    "from gluon.plots import plot_four_forecasts\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e329c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_factor = 3\n",
    "backtest_id = 2\n",
    "\n",
    "metadata, train_data, test_data = generate_backtesting_datasets(\"electricity_hourly\", backtest_id, history_factor, use_cached=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c448e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in list(train_data):\n",
    "    entry[\"target\"] = entry[\"target\"][:20, :]\n",
    "for entry in list(test_data):\n",
    "    entry[\"target\"] = entry[\"target\"][:20, :]\n",
    "entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ced2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original Energy dataset\n",
    "train_tf_entry = next(iter(list(train_data)))\n",
    "[k for k in train_tf_entry.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561a3b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(train_data)[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2f18cca",
   "metadata": {},
   "source": [
    "Create Custom Transformation on Energy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0695bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(train_data)[0][\"target\"].shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a969a3e5",
   "metadata": {},
   "source": [
    "Create the Lightning version of the TradeBOT model.\n",
    "\n",
    "The model parameters are almost all in the `model_parameters` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d29952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net_estimator = TradeBotLightEstimator(\n",
    "    num_samples = 100,\n",
    "    model_parameters= {\n",
    "        \"gamma\":0.8,\n",
    "        \"l_norm\": 2,\n",
    "        \"data_normalization\":\"standardization\",\n",
    "        \"loss_normalization\":\"series\",\n",
    "        \"series_embedding_dim\":13,\n",
    "        \"input_encoder_layers\":3,\n",
    "        \"input_encoding_normalization\":True,\n",
    "        \"encoder\": {\n",
    "            \"attention_layers\":3,\n",
    "            \"attention_heads\": 3,\n",
    "            \"attention_dim\": 4,\n",
    "            \"attention_feedforward_dim\": 12,\n",
    "        },\n",
    "        \"quantile_decoder\":{\n",
    "             \"min_u\": 0.01,\n",
    "             \"max_u\": 0.99,\n",
    "            \"attentional_quantile\": {\n",
    "                \"attention_heads\": 3,\n",
    "                \"attention_layers\": 3,\n",
    "                \"attention_dim\": 12,\n",
    "                \"mlp_layers\": 3,\n",
    "                \"mlp_dim\": 16,\n",
    "                \"resolution\": 50,\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    learning_rate = 1e-3,\n",
    "    trainer_kwargs=dict(max_epochs=3, accelerator=\"cpu\"),\n",
    "    num_series = list(train_data)[0][\"target\"].shape[0],\n",
    "    history_length = history_factor * metadata.prediction_length,\n",
    "    prediction_length = metadata.prediction_length,\n",
    "    freq = metadata.freq,\n",
    "    cdf_normalization = True,\n",
    "    #num_parallel_samples = 100,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29beabd2",
   "metadata": {},
   "source": [
    "Train the model. Lightning automatically send the model to GPU if the accelerator is set accordingly, and send it back to CPU after training.\n",
    "\n",
    "The tuner can automatically find the maximum batch size which can fit in memory, but we give it a maximum number of trials since it does not stop as it goes above the number of samples per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913700c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictor = net_estimator.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c068925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=test_data, predictor=predictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf64e1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.test(datamodule=data_module, ckpt_path='best')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a23844e9",
   "metadata": {},
   "source": [
    "Reduce the batch size parameter, since TACTiS uses a lot of GPU memory during inference due to the many parallel samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec3cc11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_module.batch_size = 10\n",
    "predictions = trainer.predict(datamodule=data_module, ckpt_path='best')\n",
    "predictions = torch.cat(predictions, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4997c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps, ground_truths = data_module.predict_groundtruth(include_hist=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea72333e",
   "metadata": {},
   "source": [
    "Plotting the training and validation loss functions during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5504c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(logger.log_dir, \"metrics.csv\"))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(\n",
    "    df[~df.train_loss.isna()].epoch, df[~df.train_loss.isna()].train_loss, label=\"train\",\n",
    ")\n",
    "plt.plot(\n",
    "    df[~df.valid_loss.isna()].epoch, df[~df.valid_loss.isna()].valid_loss, label=\"validation\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcf2a3cf",
   "metadata": {},
   "source": [
    "Plotting a few forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_series(samples, target, timesteps, index):\n",
    "    s_samples = samples[index, :, :].cpu().numpy()\n",
    "    s_timesteps = timesteps[:].cpu().numpy()\n",
    "    s_target = target[index, :].cpu().numpy()\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    for zorder, quant, color, label in [\n",
    "        [1, 0.05, (0.75,0.75,1), \"5%-95%\"],\n",
    "        [2, 0.10, (0.25,0.25,1), \"10%-90%\"],\n",
    "        [3, 0.25, (0,0,0.75), \"25%-75%\"],\n",
    "    ]:\n",
    "        plt.fill_between(\n",
    "            s_timesteps,\n",
    "            np.quantile(s_samples, quant, axis=1),\n",
    "            np.quantile(s_samples, 1 - quant, axis=1),\n",
    "            facecolor=color,\n",
    "            interpolate=True,\n",
    "            label=label,\n",
    "            zorder=zorder,\n",
    "        )\n",
    "    \n",
    "    plt.plot(\n",
    "        s_timesteps,\n",
    "        np.quantile(s_samples, 0.5, axis=1),\n",
    "        color=(0.5,0.5,0.5),\n",
    "        linewidth=3,\n",
    "        label=\"50%\",\n",
    "        zorder=4,\n",
    "    )\n",
    "    \n",
    "    plt.plot(s_timesteps, s_target, color=(0, 0, 0), linewidth=2, zorder=5, label=\"ground truth\")\n",
    "    \n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    order = [0, 1, 2, 3, 4]\n",
    "    plt.legend([handles[idx] for idx in order], [labels[idx] for idx in order])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efee5698",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred_idx, var_idx in [(13, 3), (5, 7), (2, 8), (16, 0)]:\n",
    "    plot_single_series(predictions[pred_idx], ground_truths[pred_idx], timesteps[pred_idx], var_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
