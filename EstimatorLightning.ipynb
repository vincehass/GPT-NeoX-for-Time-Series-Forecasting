{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19104e62",
   "metadata": {},
   "source": [
    "# Pytorch Lightning Estimator interface for TradeBot transformer \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa85db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/nhassen/Documents/ProjectQuant/MyRepos/test/GPT-NeoX-for-Time-Series-Forecasting/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d8bc993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nhassen/opt/anaconda3/envs/env_LLMTS/lib/python3.9/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from itertools import islice\n",
    "from GPT_NEO.lightning_module import TradeBotLightning\n",
    "from GPT_NEO.estimator import TradeBotLightEstimator\n",
    "from GPT_NEO.estimator import TradeBotLightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45592614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gluon.dataset import generate_backtesting_datasets\n",
    "from gluon.metrics import compute_validation_metrics\n",
    "from gluon.plots import plot_four_forecasts\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3e329c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download electricity_hourly_dataset.zip:: 11.3MB [00:04, 2.79MB/s]\n",
      "creating json files: 100%|██████████| 321/321 [00:00<00:00, 309866.88it/s]\n"
     ]
    }
   ],
   "source": [
    "history_factor = 3\n",
    "backtest_id = 2\n",
    "\n",
    "metadata, train_data, test_data = generate_backtesting_datasets(\"electricity_hourly\", backtest_id, history_factor, use_cached=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c448e5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': array([[   0.,    0.,    0., ...,   11.,   11.,   12.],\n",
       "        [   0.,    0.,    0., ...,   97.,   88.,   82.],\n",
       "        [   0.,    0.,    0., ...,    8.,    8.,    8.],\n",
       "        ...,\n",
       "        [   0.,    0.,    0., ..., 1437., 1404., 1134.],\n",
       "        [   0.,    0.,    0., ...,  124.,  109.,  116.],\n",
       "        [   0.,    0.,    0., ...,  178.,  151.,  139.]], dtype=float32),\n",
       " 'start': Period('2014-11-28 00:00', 'H'),\n",
       " 'feat_static_cat': array([0], dtype=int32)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for entry in list(train_data):\n",
    "    entry[\"target\"] = entry[\"target\"][:24, :]\n",
    "for entry in list(test_data):\n",
    "    entry[\"target\"] = entry[\"target\"][:24, :]\n",
    "entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ced2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target', 'start', 'feat_static_cat']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Original Energy dataset\n",
    "train_tf_entry = next(iter(list(train_data)))\n",
    "[k for k in train_tf_entry.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "561a3b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': array([[  14.,   18.,   21., ...,   11.,   12.,   10.],\n",
       "        [  69.,   92.,   96., ...,  100.,   94.,   86.],\n",
       "        [ 234.,  312.,  312., ...,    8.,    8.,    8.],\n",
       "        ...,\n",
       "        [ 885., 1074.,  936., ..., 1301., 1193.,  979.],\n",
       "        [ 122.,  150.,  149., ...,  126.,  118.,  113.],\n",
       "        [ 102.,  127.,  117., ...,  142.,  129.,  106.]], dtype=float32),\n",
       " 'start': Period('2012-01-01 00:00', 'H'),\n",
       " 'feat_static_cat': array([0], dtype=int32)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_data)[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a969a3e5",
   "metadata": {},
   "source": [
    "Create the Lightning version of the TradeBOT model.\n",
    "\n",
    "The model parameters are almost all in the `model_parameters` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d29952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net_estimator = TradeBotLightEstimator(\n",
    "    num_samples = 100,\n",
    "    model_parameters= {\n",
    "        \"gamma\":0.8,\n",
    "        \"l_norm\": 2,\n",
    "        \"data_normalization\":\"standardization\",\n",
    "        \"loss_normalization\":\"series\",\n",
    "        \"series_embedding_dim\":13,\n",
    "        \"input_encoder_layers\":3,\n",
    "        \"input_encoding_normalization\":True,\n",
    "        \"encoder\": {\n",
    "            \"attention_layers\":3,\n",
    "            \"attention_heads\": 3,\n",
    "            \"attention_dim\": 4,\n",
    "            \"attention_feedforward_dim\": 12,\n",
    "        },\n",
    "        \"quantile_decoder\":{\n",
    "             \"min_u\": 0.01,\n",
    "             \"max_u\": 0.99,\n",
    "            \"attentional_quantile\": {\n",
    "                \"attention_heads\": 3,\n",
    "                \"attention_layers\": 3,\n",
    "                \"attention_dim\": 12,\n",
    "                \"mlp_layers\": 3,\n",
    "                \"mlp_dim\": 16,\n",
    "                \"resolution\": 50,\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    learning_rate = 1e-3,\n",
    "    trainer_kwargs=dict(max_epochs=3, accelerator=\"cpu\"),\n",
    "    num_series = list(train_data)[0][\"target\"].shape[0],\n",
    "    history_length = history_factor * metadata.prediction_length,\n",
    "    prediction_length = metadata.prediction_length,\n",
    "    freq = metadata.freq,\n",
    "    cdf_normalization = True,\n",
    "    num_parallel_samples = 100,\n",
    "    batch_size = 32,\n",
    "    num_batches_per_epoch = 4,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29beabd2",
   "metadata": {},
   "source": [
    "Train the model. Lightning automatically send the model to GPU if the accelerator is set accordingly, and send it back to CPU after training.\n",
    "\n",
    "The tuner can automatically find the maximum batch size which can fit in memory, but we give it a maximum number of trials since it does not stop as it goes above the number of samples per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "913700c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/nhassen/opt/anaconda3/envs/env_LLMTS/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "/Users/nhassen/opt/anaconda3/envs/env_LLMTS/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:72: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | net  | TradingBot | 32.1 K\n",
      "------------------------------------\n",
      "32.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.1 K    Total params\n",
      "0.129     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c738f9ab773a40079feb09957fc36e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nhassen/opt/anaconda3/envs/env_LLMTS/lib/python3.9/site-packages/gluonts/transform/convert.py:566: RuntimeWarning: divide by zero encountered in divide\n",
      "  x_diff == 0.0, np.zeros_like(x_diff), y_diff / x_diff\n",
      "Epoch 0, global step 30: 'train_loss' reached -5.59897 (best -5.59897), saving model to '/Users/nhassen/Documents/ProjectQuant/MyRepos/test/GPT-NeoX-for-Time-Series-Forecasting/lightning_logs/version_37/checkpoints/epoch=0-step=30.ckpt' as top 1\n",
      "/Users/nhassen/opt/anaconda3/envs/env_LLMTS/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "predictor = net_estimator.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c068925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=test_data, predictor=predictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf64e1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forecasts = list(forecast_it)\n",
    "tss = list(ts_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4997c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator()\n",
    "agg_metrics, ts_metrics = evaluator(\n",
    "    iter(tss), iter(forecasts), num_series=len(test_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068a3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df49747",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = compute_validation_metrics(\n",
    "    predictor=predictor,\n",
    "    dataset=test_data,\n",
    "    window_length=net_estimator.history_length + net_estimator.prediction_length,\n",
    "    num_samples=100,\n",
    "    split=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c9dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bff526",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=test_data, predictor=predictor, num_samples=100\n",
    ")\n",
    "forecasts = list(forecast_it)\n",
    "targets = list(ts_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ddc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_four_forecasts(\n",
    "    forecasts=forecasts,\n",
    "    targets=targets,\n",
    "    selection=[(0, 0), (1, 5), (2, 10), (3, 15)],\n",
    "    tick_freq=\"day\",\n",
    "    history_length=net_estimator.history_length,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
